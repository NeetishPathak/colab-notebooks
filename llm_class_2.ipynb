{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bes6UFVS6jWq"
      },
      "source": [
        "## This is a sample streamlit app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAM8ev2O62pm",
        "outputId": "0f222574-c2da-4892-c4ba-e706099f5de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q cassio datasets langchain langchain_community openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h38FfHXFcws7",
        "outputId": "86a107a0-69f9-45e6-db4d-5ac80934606a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wynLwncehgMF"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OQFoYFYlfcGF"
      },
      "outputs": [],
      "source": [
        "# !wget https://redis.io/wp-content/uploads/2021/12/caching-at-scale-with-redis-updated-2021-12-04.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zkaFVZ226nMg"
      },
      "outputs": [],
      "source": [
        "# Langchain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "# Support dataset retrieval from huggingface\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Initialize DB connection to langchain\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgiPX1CkdAIA"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "ASTRA_DB_APPLICATION_TOKEN = userdata.get('ASTRA_DB_APPLICATION_TOKEN')\n",
        "ASTRA_DB_ID = userdata.get('ASTRA_DB_ID')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "EmzjRCnF6xuk"
      },
      "outputs": [],
      "source": [
        "pdfreader = PdfReader('/content/redis.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "farqDZLr7TRy"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMvsA8JUig-Y"
      },
      "outputs": [],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4L9_fYtziiVv"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "bx1IGMg0i72B"
      },
      "outputs": [],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7u06qjw7iskw"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "l03cm9WyjC8C"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "SDVCzYbFjFCg"
      },
      "outputs": [],
      "source": [
        "# texts[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zFgaIbjGtN",
        "outputId": "4f978251-a574-49a4-9832-4f580f100dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inserted 197 headlines.\n"
          ]
        }
      ],
      "source": [
        "astra_vector_store.add_texts(texts)\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrQJ3deCjXO_",
        "outputId": "5c684aec-8184-4844-b0da-f5675249f7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): what is redis\n",
            "\n",
            "QUESTION: \"what is redis\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANSWER: \"Redis is an in-memory database and Database-as-a-Service (DBaaS) that is consistently ranked as a leader in top analyst reports on NoSQL, operational databases, and Database-as-a-Service (DBaaS). It is trusted by thousands of enterprise customers and is used for high-speed transactions, job and queue management, user session stores, and real-time data ingest. It is available in public and private clouds, as downloadable software, in containers, and for hybrid cloud/on-premises deployments.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [0.9109] \"Redis, consistently ranked as a leader in top analyst reports on NoSQL, in-\n",
            "memory d ...\"\n",
            "    [0.9109] \"Redis, consistently ranked as a leader in top analyst reports on NoSQL, in-\n",
            "memory d ...\"\n",
            "    [0.8995] \"means it is fast. Redis is often used as a cache frontend for some other, slower but ...\"\n",
            "    [0.8993] \"means it is fast. Redis is often used as a cache frontend for some other, slower but ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_WIE5tglpZg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
